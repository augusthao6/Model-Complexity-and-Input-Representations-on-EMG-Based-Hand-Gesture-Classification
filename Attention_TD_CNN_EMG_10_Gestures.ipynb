{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_kQuOUWdQRf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyM_SViCYToa",
        "outputId": "65785bac-47c5-4e5e-ea3a-c4b70b712816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m189.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n",
            "Collecting pyentrp\n",
            "  Downloading pyentrp-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.26 in /usr/local/lib/python3.11/dist-packages (from pyentrp) (2.0.2)\n",
            "Downloading pyentrp-1.0.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyentrp\n",
            "Successfully installed pyentrp-1.0.0\n",
            "Collecting eeglib\n",
            "  Downloading eeglib-0.4.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastdtw (from eeglib)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from eeglib) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from eeglib) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from eeglib) (2.2.2)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.11/dist-packages (from eeglib) (4.5.0)\n",
            "Collecting pyedflib (from eeglib)\n",
            "  Downloading pyedflib-0.1.40.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from eeglib) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from eeglib) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->eeglib) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->eeglib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->eeglib) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->eeglib) (2025.2)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2->eeglib) (3.9.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->eeglib) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->eeglib) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->eeglib) (1.17.0)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.11/dist-packages (from python-utils>=3.8.1->progressbar2->eeglib) (4.13.2)\n",
            "Downloading eeglib-0.4.1.1-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fastdtw, pyedflib\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp311-cp311-linux_x86_64.whl size=542085 sha256=5bae3f7e74dc63e20444ff549d499bc88f9d69b5bb76ef123e0e662e63236e00\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/8a/f6/fd3df9a9714677410a5ccbf3ca519e66db4a54a1c46ea95332\n",
            "  Building wheel for pyedflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyedflib: filename=pyedflib-0.1.40-cp311-cp311-linux_x86_64.whl size=2734981 sha256=5aaf5995dda11998f484489145030f6621c69a918242219993e7e76fab05fefb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/df/d6/88ce619bde055ebffebae5380645802eca490817853b60b45b\n",
            "Successfully built fastdtw pyedflib\n",
            "Installing collected packages: pyedflib, fastdtw, eeglib\n",
            "Successfully installed eeglib-0.4.1.1 fastdtw-0.3.4 pyedflib-0.1.40\n"
          ]
        }
      ],
      "source": [
        "#Do this at the start of every runtime\n",
        "!pip install PyWavelets\n",
        "!pip install pyentrp\n",
        "!pip install eeglib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VTrJOayVs8k"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from scipy.stats import skew, kurtosis\n",
        "import numpy as np\n",
        "import pywt\n",
        "import csv\n",
        "from pyentrp import entropy as ent\n",
        "import statsmodels.api as sm\n",
        "import eeglib\n",
        "import scipy.signal as signal\n",
        "\n",
        "import scipy.io as spio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import svm\n",
        "\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6H7a7BbRG16",
        "outputId": "ba629294-bb3b-4de8-d296-da1c94e0d7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! cp -r /content/drive/MyDrive/NinaproDB1 /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbdRba_8ushz"
      },
      "source": [
        "## Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWyVz-YRRtiL"
      },
      "outputs": [],
      "source": [
        "###### Functions ##########\n",
        "\n",
        "#This script contains all the required functions to run the classifier model scripts and the Sort script\n",
        "\n",
        "#Function to segment sEMG data into defined time windows\n",
        "#takes data to be segmented as input\n",
        "def windowmaker(data):\n",
        "\n",
        "        #define window parameters and sampling frequency\n",
        "        window_length = 0.5\n",
        "        overlap = 0.7\n",
        "        fs = 100\n",
        "\n",
        "        num_samp = int(fs*window_length) #calculate number of samples in each window\n",
        "        next_window = int(num_samp - num_samp*overlap) #calculate sample number at which next window starts\n",
        "        windows = []\n",
        "        window_start = 0\n",
        "        while window_start + num_samp < len(data): #ensure window length is within data\n",
        "                window_end = window_start + num_samp  #set end of window\n",
        "                subwindow = data[window_start:window_end] #generate data window\n",
        "                windows.append(subwindow) #add subwindow to group of windows\n",
        "                window_start = window_start + next_window #set starting point of next window\n",
        "        windows = np.array(windows).transpose(0, 2, 1)\n",
        "        return windows\n",
        "\n",
        "\n",
        "def fft_feature_extraction(windows):\n",
        "    fft_features = []\n",
        "    for window in windows:\n",
        "        # Apply FFT along time axis\n",
        "        fft_magnitude = np.abs(np.fft.rfft(window, axis=1))  # shape: (channels, freq_bins)\n",
        "        fft_features.append(fft_magnitude)\n",
        "    return np.array(fft_features)  # shape: (num_windows, channels, freq_bins)\n",
        "\n",
        "\n",
        "def dwt_feature_extraction(windows, wavelet='db4', level=3):\n",
        "    dwt_features = []\n",
        "    for window in windows:\n",
        "        # window shape: (channels, time)\n",
        "        channel_coeffs = []\n",
        "        for channel_data in window:\n",
        "            # Perform multilevel DWT on one channel\n",
        "            coeffs = pywt.wavedec(channel_data, wavelet=wavelet, level=level)\n",
        "            # Concatenate all coefficients (approx + detail)\n",
        "            coeff_vector = np.concatenate(coeffs)\n",
        "            channel_coeffs.append(coeff_vector)\n",
        "        dwt_features.append(channel_coeffs)\n",
        "    return np.array(dwt_features)  # shape: (num_windows, channels, dwt_feature_len)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Function to create training, validation and feature CSV files\n",
        "def makecsv(data,subject, feature_type=\"time\"):\n",
        "\n",
        "        #define gestures to add to CSV files\n",
        "        gesturelist = [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "        #create training set CSV file\n",
        "        f_name = \"subject{}_{}_train_data.csv\".format(subject, feature_type)  #create\n",
        "        f = open(f_name,\"w\") #open CSV file\n",
        "        writer = csv.writer(f)\n",
        "        trainrep = [1,3,5,6,8,9,10]\n",
        "        for i in gesturelist:  #iterate through gestures\n",
        "                for k in trainrep:   #iterate through gesture reptitions\n",
        "                        window_num = 0\n",
        "                        for window in data[\"gesture{}\".format(i)][\"repitition{}\".format(k)]:\n",
        "                                if window_num <1000:  # conditional statement to cap number samples for each gesture if desired\n",
        "                                        row = []\n",
        "                                        # Apply FFT if needed\n",
        "                                        if feature_type == \"fft\":\n",
        "                                            window = fft_feature_extraction([window])[0]\n",
        "                                        if feature_type == \"dwt\":\n",
        "                                            window = dwt_feature_extraction([window])[0]\n",
        "                                        wl = list(window)\n",
        "                                        gest = [i]\n",
        "                                        dat = gest + wl\n",
        "                                        writer.writerow(dat) #add data window and label to CSV\n",
        "                                        window_num = window_num +1\n",
        "                print(i,\"finished\")\n",
        "        f.close\n",
        "\n",
        "\n",
        "        #create validation set CSV file\n",
        "        f_name = \"subject{}_{}_validation_data.csv\".format(subject, feature_type)\n",
        "        f = open(f_name,\"w\") #open CSV file\n",
        "        writer = csv.writer(f)\n",
        "        val_rep = [2,4]\n",
        "        for i in gesturelist:   #iterate through gestures\n",
        "                for k in val_rep:   #iterate through gesture reptitions\n",
        "                        window_num = 0\n",
        "                        for window in data[\"gesture{}\".format(i)][\"repitition{}\".format(k)]:\n",
        "                                if window_num <1000:\n",
        "                                        row = []\n",
        "                                        # Apply FFT if needed\n",
        "                                        if feature_type == \"fft\":\n",
        "                                            window = fft_feature_extraction([window])[0]\n",
        "                                        if feature_type == \"dwt\":\n",
        "                                            window = dwt_feature_extraction([window])[0]\n",
        "                                        wl = list(window)\n",
        "                                        gest = [i]\n",
        "                                        dat = gest + wl\n",
        "                                        writer.writerow(dat) #add data window and label to CSV\n",
        "                                        window_num = window_num +1\n",
        "        f.close\n",
        "\n",
        "        #create test set CSV file\n",
        "        f_name = \"subject{}_{}_test_data.csv\".format(subject, feature_type)\n",
        "        f = open(f_name,\"w\") #open CSV file\n",
        "        writer = csv.writer(f)\n",
        "        for i in gesturelist:\n",
        "                k = 7\n",
        "                window_num = 0\n",
        "                for window in data[\"gesture{}\".format(i)][\"repitition{}\".format(k)]:\n",
        "                        if window_num <1000:\n",
        "                                row = []\n",
        "                                # Apply FFT if needed\n",
        "                                if feature_type == \"fft\":\n",
        "                                    window = fft_feature_extraction([window])[0]\n",
        "                                if feature_type == \"dwt\":\n",
        "                                    window = dwt_feature_extraction([window])[0]\n",
        "                                wl = list(window)\n",
        "                                gest = [i]\n",
        "                                dat = gest + wl\n",
        "                                writer.writerow(dat) #add data window and label to CSV\n",
        "                                window_num = window_num +1\n",
        "        f.close\n",
        "\n",
        "\n",
        "#Function to read CSV files and create input and target arrays\n",
        "#for direct input into DL classifier models, takes CSV file and the\n",
        "#the type of CSV file e.g. \"train\" as inputs\n",
        "\n",
        "def inputstargets(subject,type, feature_type=\"time\"):\n",
        "\n",
        "        #define input and target lists for classifier input\n",
        "        inputs= []\n",
        "        targets=[]\n",
        "\n",
        "        #open csv file specific to subject\n",
        "        data_file = open(\"subject{}_{}_{}_data.csv\".format(subject,feature_type, type), 'r') #open CSV file from stored location\n",
        "        data_list = list(csv.reader(data_file)) #read csv file\n",
        "        data_file.close()\n",
        "\n",
        "        #extract and convert values from csv file into a list of float input values\n",
        "        #and integer target values\n",
        "\n",
        "        for data in data_list: #iterate through data windows stored in CSV\n",
        "                window = []\n",
        "                for j in range(1,11):\n",
        "                        res = data[j].strip('][').split(' ')\n",
        "                        res2 = []\n",
        "                        for a in res:\n",
        "                                if a != '':\n",
        "                                        float(a)\n",
        "                                        res2.append(a)\n",
        "                        res2 = np.asarray(res2, dtype=float)\n",
        "                        window.append(res2)\n",
        "                inputs.append(window)\n",
        "                gesture = int(data[0]) #extract gesture label from CSV\n",
        "                targets.append(gesture)\n",
        "        return inputs, targets\n",
        "\n",
        "#Function to renumber gestures from DB1 Ex2 to be in 0-9 range\n",
        "def asign_ex2_gesture(gesture):\n",
        "        if gesture == 5:\n",
        "                assigned = 1\n",
        "        elif gesture == 6:\n",
        "                assigned = 2\n",
        "        elif gesture == 7:\n",
        "                assigned = 3\n",
        "        elif gesture == 11:\n",
        "                assigned = 4\n",
        "        elif gesture == 14:\n",
        "                assigned = 5\n",
        "        elif gesture == 16:\n",
        "                assigned = 6\n",
        "        return assigned\n",
        "\n",
        "#Function to renumber gestures from DB1 Ex3 to be in 10-14 range\n",
        "def asign_ex3_gesture(gesture):\n",
        "        if gesture == 1:\n",
        "                assigned = 7\n",
        "        elif gesture == 2:\n",
        "                assigned = 8\n",
        "        elif gesture == 14:\n",
        "                assigned = 9\n",
        "        elif gesture == 17:\n",
        "                assigned = 10\n",
        "        return assigned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5J1vNk-uwPP"
      },
      "source": [
        "## Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDWnynrMu4dj",
        "outputId": "214782b9-8b3c-47dc-bac0-624be4ba401f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n",
            "0 finished\n",
            "1 finished\n",
            "2 finished\n",
            "3 finished\n",
            "4 finished\n",
            "5 finished\n",
            "6 finished\n",
            "7 finished\n",
            "8 finished\n",
            "9 finished\n"
          ]
        }
      ],
      "source": [
        "##### Sort ###########\n",
        "\n",
        "#This script loads and segments the sEMG data from the Matlab files provided by the Ninapro DB1 database\n",
        "#For each of the 27 subjects this produces three CSV files for each subject: training, validation and test.\n",
        "#An additional three CSV files are also created containing the extracted features of the specified feature set\n",
        "\n",
        "\n",
        "#Create dictionaries, lists, and arrays for storing and sorting data values\n",
        "emg_data = {}\n",
        "spec_emg_data = {}\n",
        "endlist = []\n",
        "#List of desired gestures for classification within each exercise - 10 gestures\n",
        "EX2_gest = [5,6,7,11,14,16]\n",
        "EX3_gest = [1,2,14,17]\n",
        "\n",
        "#Define number of subjects\n",
        "subject_list = list(range(1,28))\n",
        "\n",
        "#Iterate through all subjects in database and load subject EMG matlab files into dictionaries\n",
        "for i in subject_list:\n",
        "    emg_data[\"subject{}\".format(i)]={}\n",
        "    emg_data[\"subject{}\".format(i)][\"ex2\"]= spio.loadmat(\"/content/NinaproDB1/s{}/S{}_A1_E2.mat\".format(i,i),variable_names = \"emg\") #Load files from stored location\n",
        "    emg_data[\"subject{}\".format(i)][\"ex3\"]= spio.loadmat(\"/content/NinaproDB1/s{}/S{}_A1_E3.mat\".format(i,i),variable_names = \"emg\") #Load files from stored location\n",
        "\n",
        "\n",
        "    #Create nested dictionaries to store gesture classes for corresponding EMG data and specific EMG data for each gesture for each subject\n",
        "\n",
        "    #Access gesure classes for each subject\n",
        "    emg_data[\"subject{}\".format(i)][\"ex2\"][\"r\"] = {}\n",
        "    emg_data[\"subject{}\".format(i)][\"ex2\"][\"r\"]= spio.loadmat(\"/content/NinaproDB1/s{}/S{}_A1_E2.mat\".format(i,i),variable_names= \"restimulus\")\n",
        "\n",
        "    spec_emg_data[\"subject{}\".format(i)]={} #Instantiate nested subject specific EMG dicitionary\n",
        "\n",
        "    #For each desired gesture in EX2 for specific subject store, corresponding segmented EMG data in nested dictionary\n",
        "    for l in EX2_gest:\n",
        "        a = asign_ex2_gesture(l) #Use function to renumber ex2 gestures between 0-9\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)] = {}\n",
        "        loclist = [] #Create list to store positions of specific gesture data within exercise 1 data\n",
        "        loc = np.where(emg_data[\"subject{}\".format(i)][\"ex2\"][\"r\"][\"restimulus\"]==l) #Search through class data to find locations of specific gesture data within exercise 2 data\n",
        "        #Determine locations of sEMG data for each repetition of the gesture\n",
        "        loclist.append(loc[0][0])\n",
        "        for x,y in zip(loc[0][::],loc[0][1::]): #Find gesture locations at the border between the gesture and rest\n",
        "            if y-x != 1:\n",
        "                loclist.append(x)\n",
        "                loclist.append(y)\n",
        "        loclist.append(loc[0][-1])#Append last value\n",
        "\n",
        "        #Use gesture 5 positions in order to extract rest position data as there is no specific\n",
        "        #Exercise for rest data hence it must be extracted from breaks between gesture repetitions\n",
        "        if l ==5:\n",
        "            restlist = loclist\n",
        "            #Add rest data to nested dictionary taken from rests periods between repetitions of the first gesture\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"] = {}\n",
        "\n",
        "            #Segment each rest gesture repetition using \"windowmaker\" function and store in specific nested dictionary entry\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition1\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[1]+1:restlist[2]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition2\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[3]+1:restlist[4]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition3\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[5]+1:restlist[6]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition4\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[7]+1:restlist[8]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition5\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[9]+1:restlist[10]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition6\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[11]+1:restlist[12]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition7\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[13]+1:restlist[14]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition8\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[15]+1:restlist[16]])\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition9\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[17]+1:restlist[18]])\n",
        "\n",
        "\n",
        "        #Retreive 10th rest repetition from gesture 6 data\n",
        "        if l ==6:\n",
        "            restlist = loclist\n",
        "            spec_emg_data[\"subject{}\".format(i)][\"gesture0\"][\"repitition10\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][restlist[1]+1:restlist[2]])\n",
        "\n",
        "\n",
        "        #Segment each gesture repetition using \"windowmaker\" function and store it in specific nested dictionary entry\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition1\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[0]:loclist[1]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition2\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[2]:loclist[3]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition3\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[4]:loclist[5]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition4\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[6]:loclist[7]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition5\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[8]:loclist[9]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition6\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[10]:loclist[11]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition7\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[12]:loclist[13]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition8\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[14]:loclist[15]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition9\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[16]:loclist[17]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(a)][\"repitition10\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex2\"][\"emg\"][loclist[18]:loclist[19]+1])\n",
        "\n",
        "\n",
        "    #Delete unused variables to increase computational efficiency\n",
        "    del emg_data[\"subject{}\".format(i)][\"ex2\"]\n",
        "\n",
        "    ##Repeat same process for EX3 gestures ##\n",
        "\n",
        "    #Access gesture classes for each subject\n",
        "    emg_data[\"subject{}\".format(i)][\"ex3\"][\"r\"]= {}\n",
        "    emg_data[\"subject{}\".format(i)][\"ex3\"][\"r\"] = spio.loadmat(\"/content/NinaproDB1/s{}/S{}_A1_E3.mat\".format(i,i),variable_names = \"restimulus\")\n",
        "\n",
        "\n",
        "    for j in EX3_gest:\n",
        "        b = asign_ex3_gesture(j) #Use function to renumber ex3 gestures between 10-14\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)] = {}\n",
        "        loclist = [] #Create list to store positions of specific gesture data within exercise 3 data\n",
        "        loc = np.where(emg_data[\"subject{}\".format(i)][\"ex3\"][\"r\"][\"restimulus\"]==j) #Search through class data to find locations of specific gesture data within exercise 3 data\n",
        "        #Determine locations of sEMG data for each reptiion of the gesture\n",
        "        loclist.append(loc[0][0])\n",
        "        for x,y in zip(loc[0][::],loc[0][1::]):#Find gesture locations at the border between the gesture and rest\n",
        "            if y-x != 1:\n",
        "                loclist.append(x)\n",
        "                loclist.append(y)\n",
        "\n",
        "        loclist.append(loc[0][-1]) #Append last value\n",
        "\n",
        "        #Segment each gesture repetition using \"windowmaker\" function and store in specific nested dictionary entry\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition1\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[0]:loclist[1]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition2\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[2]:loclist[3]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition3\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[4]:loclist[5]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition4\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[6]:loclist[7]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition5\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[8]:loclist[9]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition6\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[10]:loclist[11]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition7\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[12]:loclist[13]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition8\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[14]:loclist[15]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition9\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[16]:loclist[17]+1])\n",
        "        spec_emg_data[\"subject{}\".format(i)][\"gesture{}\".format(b)][\"repitition10\"] = windowmaker(emg_data[\"subject{}\".format(i)][\"ex3\"][\"emg\"][loclist[18]:loclist[19]+1])\n",
        "\n",
        "    #Delete unused variables to increase computational efficiency\n",
        "    del emg_data[\"subject{}\".format(i)]\n",
        "\n",
        "    #create training, validation and test CSV files contianing segemented sEMG gesture data\n",
        "    #CHANGE THIS to get diff types of data\n",
        "    makecsv(spec_emg_data[\"subject{}\".format(i)],i)\n",
        "    #makecsv(spec_emg_data[\"subject{}\".format(i)],i, \"fft\")\n",
        "    #makecsv(spec_emg_data[\"subject{}\".format(i)],i, \"dwt\")\n",
        "\n",
        "   #Delete surplus variables to increase computational efficiency\n",
        "    del spec_emg_data[\"subject{}\".format(i)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention"
      ],
      "metadata": {
        "id": "4LrwSVd4LFx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "\n",
        "        #Calculate average and max pool for each channel - \"Squeeze\"\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        #Put the pools through an MLP - \"Excitation\"\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _ = x.size()\n",
        "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
        "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
        "        channel_att = self.sigmoid(avg_out + max_out).view(b, c, 1) #Add average and max out and apply sigmoid - gives us channel attention weights\n",
        "        return x * channel_att #Apply channel attention\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Conv1d(2, 1, kernel_size=kernel_size, padding=kernel_size//2) #Perform 1d convolution - gives us time domain\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        attention_input = torch.cat([avg_out, max_out], dim=1) #Concatenate avg and max out\n",
        "\n",
        "        attention_map = self.sigmoid(self.conv(attention_input)) #Perform convolution and sigmoid, giving us temporal attention weights\n",
        "\n",
        "        return x * attention_map #Apply temporal attention"
      ],
      "metadata": {
        "id": "e-18C_qTLJaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEMZqoqlWQST"
      },
      "source": [
        "# Middle CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class middleCNN(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes, dropout_rate=0.3):\n",
        "        super(middleCNN, self).__init__()\n",
        "\n",
        "        #First convolution block\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.channel_attention = ChannelAttention(32) #Add Channel Attention after first convolution block\n",
        "\n",
        "        #Second convolution block\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.spatial_attention = SpatialAttention() #Add Spatial (Temporal) Attention after second convolution block\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        #Third convolution block\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        #Global pooling and FC layers\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(128, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.dropout3 = nn.Dropout(dropout_rate)\n",
        "        self.out = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #First convolution block\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.channel_attention(x)\n",
        "\n",
        "        #Second convolution block\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        #Third convolution block\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        #Global pooling and FC layers\n",
        "        x = self.global_avg_pool(x).squeeze(-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9NCKNlqLX56Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simplest Model"
      ],
      "metadata": {
        "id": "bPW_kHnSHcjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class simplestCNN(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(simplestCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "        self.out = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.global_avg_pool(x).squeeze(-1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6UJjt5hTrOXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Complex CNN model"
      ],
      "metadata": {
        "id": "ZKOTHQ3FHa8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Self\n",
        "class complexCNN(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(complexCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(256, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.out = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.dropout3 = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.global_avg_pool(x).squeeze(-1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mjrvPI_pqjZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "19D4jTZtAEWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Define subject datasets to evaluate\n",
        "subjects = list(range(1,28))\n",
        "\n",
        "#Define lists to store data accumulated across multiple subjects\n",
        "all_acc = []\n",
        "all_train_time = []\n",
        "all_test_time = []\n",
        "all_train_latency = []\n",
        "all_test_latency = []\n",
        "all_test_loss = []\n",
        "\n",
        "#Define learning rate scheduler\n",
        "def scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.001\n",
        "    elif 50 <= epoch < 100:\n",
        "        return 0.0005\n",
        "    elif 100 <= epoch < 150:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "\n",
        "#For plotting average loss and accuracy over all subjects\n",
        "epoch_metrics = defaultdict(lambda: {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []})\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Iterate through subjects\n",
        "for subject in subjects:\n",
        "\n",
        "    #Retreive input sEMG feature data and target labels from CSV files\n",
        "    #CHANGE THIS to get different types of data when needed\n",
        "    inputs, targets = inputstargets(subject,\"train\")\n",
        "    val_inputs, val_targets = inputstargets(subject,\"validation\")\n",
        "    test_inputs, test_targets = inputstargets(subject,\"test\")\n",
        "\n",
        "    inputs = np.array(inputs)\n",
        "    val_inputs = np.array(val_inputs)\n",
        "    test_inputs = np.array(test_inputs)\n",
        "\n",
        "    if inputs.ndim == 3:\n",
        "        inputs = inputs.transpose(0, 2, 1)\n",
        "        val_inputs = val_inputs.transpose(0, 2, 1)\n",
        "        test_inputs = test_inputs.transpose(0, 2, 1)\n",
        "\n",
        "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
        "    val_inputs = torch.tensor(val_inputs, dtype=torch.float32)\n",
        "    test_inputs = torch.tensor(test_inputs, dtype=torch.float32)\n",
        "\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "    val_targets = torch.tensor(val_targets, dtype=torch.long)\n",
        "    test_targets = torch.tensor(test_targets, dtype=torch.long)\n",
        "\n",
        "    train_dataset = TensorDataset(inputs, targets)\n",
        "    val_dataset = TensorDataset(val_inputs, val_targets)\n",
        "    test_dataset = TensorDataset(test_inputs, test_targets)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    #Initiate type of model - Change depending on model we are testing\n",
        "    model = middleCNN(input_channels=inputs.shape[1], num_classes=10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_time_start = time.time()\n",
        "\n",
        "    #Training loop\n",
        "    for epoch in range(200):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        lr = scheduler(epoch)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print(f\"\\n Epoch {epoch+1}: Learning Rate = {lr}\")\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "        train_loss = total_loss / total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                outputs = model(xb)\n",
        "                loss = criterion(outputs, yb)\n",
        "\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_correct += predicted.eq(yb).sum().item()\n",
        "                val_total += yb.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"Subject {subject} | Epoch {epoch+1}/200 | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "        epoch_metrics[epoch]['loss'].append(train_loss)\n",
        "        epoch_metrics[epoch]['val_loss'].append(val_loss)\n",
        "        epoch_metrics[epoch]['accuracy'].append(train_acc)\n",
        "        epoch_metrics[epoch]['val_accuracy'].append(val_acc)\n",
        "\n",
        "    train_time = time.time() - train_time_start\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    test_loss = 0\n",
        "    Actual_Class, Predicted_Class = [], []\n",
        "\n",
        "    test_start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            test_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "            Predicted_Class.extend(predicted.cpu().tolist())\n",
        "            Actual_Class.extend(yb.cpu().tolist())\n",
        "\n",
        "    test_time = time.time() - test_start_time\n",
        "    test_loss /= total\n",
        "\n",
        "    print(f\"Subject {subject} | Test Accuracy: {correct / total:.4f} | Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "\n",
        "    all_acc.append(correct / total)\n",
        "    all_train_time.append(train_time)\n",
        "    all_test_time.append(test_time)\n",
        "    all_test_loss.append(test_loss)\n",
        "\n",
        "    train_latency = train_time / len(train_dataset)\n",
        "    test_latency = test_time / len(test_dataset)\n",
        "    all_train_latency.append(train_latency)\n",
        "    all_test_latency.append(test_latency)\n",
        "\n",
        "    print(classification_report(Actual_Class, Predicted_Class))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(Actual_Class, Predicted_Class), display_labels=[str(i) for i in range(10)])\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.show()\n",
        "\n",
        "#Save individual test results to a CSV\n",
        "with open(\"individual_test_results_TD_10_AttentionCNN1.csv\", 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Subject', 'Test Accuracy', 'Test Loss', 'Test Time', 'Train Latency', 'Test Latency'])\n",
        "\n",
        "    for i, subject in enumerate(subjects):\n",
        "        writer.writerow([subject, all_acc[i], all_test_loss[i], all_test_time[i], all_train_latency[i], all_test_latency[i]])\n",
        "\n",
        "print(\"Individual test results have been saved to 'individual_test_results_TD_10_AttentionCNN1.csv'.\")\n",
        "\n",
        "#Average metrics per epoch\n",
        "avg_metrics = {\n",
        "    'loss': [np.mean(epoch_metrics[e]['loss']) for e in sorted(epoch_metrics)],\n",
        "    'val_loss': [np.mean(epoch_metrics[e]['val_loss']) for e in sorted(epoch_metrics)],\n",
        "    'accuracy': [np.mean(epoch_metrics[e]['accuracy']) for e in sorted(epoch_metrics)],\n",
        "    'val_accuracy': [np.mean(epoch_metrics[e]['val_accuracy']) for e in sorted(epoch_metrics)],\n",
        "}\n",
        "\n",
        "avg_metrics_df = pd.DataFrame(avg_metrics)\n",
        "avg_metrics_df.to_csv(\"avg_metrics_per_epoch_TD_10_AttentionCNN1.csv\", index_label=\"epoch\")\n",
        "\n",
        "!cp /content/avg_metrics_per_epoch_TD_10_AttentionCNN1.csv /content/drive/MyDrive/Models\n",
        "!cp /content/individual_test_results_TD_10_AttentionCNN1.csv /content/drive/MyDrive/Models\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(avg_metrics_df['loss'], label='Avg Training Loss')\n",
        "plt.plot(avg_metrics_df['val_loss'], label='Avg Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Average Loss vs Epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(avg_metrics_df['accuracy'], label='Avg Training Acc')\n",
        "plt.plot(avg_metrics_df['val_accuracy'], label='Avg Validation Acc')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Average Accuracy vs Epoch\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KmYvo8IwAGpU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "Z_kQuOUWdQRf",
        "BbdRba_8ushz",
        "4LrwSVd4LFx2",
        "iEMZqoqlWQST",
        "ZKOTHQ3FHa8w",
        "19D4jTZtAEWN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}